{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Are those . . . more bias / variance conceptual questions??"]}, {"cell_type": "markdown", "metadata": {}, "source": ["![](viz/cant_stop.gif)\n", "\n", "### Before looking at the solution branch, check your answers against \n", "### someone else in the cohort\n", "\n", "\n", "\n", "#### Fill in the following blanks for definitions of `bias` and `variance`\n", "\n", "We have a situation where we have multiple samples and one algorithm.\n", "\n", "For each sample, we train the algo on that sample, then make a prediction\n", "for a single new observation the algo wasn't trained on\n", "\n", "Let's define 'bias' and 'variance' in terms of the different predictions \n", "generated by the algo trained on different samples.\n", "\n", "**Bias**: bias refers to the average _________\n", "\n", "If we had a model with low bias, \n", "the average ________ would _________\n", "\n", "If we had a model with high bias,\n", "the average _________ would ________\n", "\n", "\n", "\n", "**Variance**: variance refers to the average _________\n", "\n", "If we had a model with low variance, \n", "the average ________ would _________\n", "\n", "If we had a model with high variance,\n", "the average ________ would _________"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "'''\n", "Bias: bias refers to the average difference between a prediction \n", "and its real value.\n", "\n", "If we had a model with high bias,\n", "the average predicted value would have a high difference with the  \n", "average real value\n", "\n", "If we had a model with low bias,\n", "the average predicted value would have a low difference with the \n", "average real value\n", "\n", "Variance: variance refers to the average difference between one \n", "model's prediction and the average prediction / \"expected value\" \n", "of all the predictions \n", "\n", "If we had a model with low variance,\n", "the average difference between a model's prediction and the \n", "average prediction would be small\n", "\n", "If we had a model with high variance,\n", "the average difference between a model's prediction and the\n", "average prediction would be high\n", "'''"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### What is \"overfitting\"?  What is \"underfitting\"?\n", "\n", "Bonus points for including discussion of \"irreducible \n", "error\" in how overfitting occurs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "'''\n", "Overfitting is when the model is trained too well on the training data. \n", "The parameters of the model fit too closely to the training data and don't\n", "generalize well to data the model wasn't trained on.\n", "\n", "BONUS POINTS: overfitting occurs when \"irreducible error\" is taken as\n", "part of the underlying structure of the data-generating process, instead\n", "of an exogenous component added to that process \n", "\n", "Underfitting is when the model doesn't adequately learn the underlying \n", "structure of the relationships among variables.  \n", "'''"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Discuss how underfitting relates to bias and/or variance\n", "\n", "#### Discuss how overfitting relates to bias and/or variance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "'''\n", "When a model underfits, it is exhibiting high bias.  It is failing to \n", "adequately capture the underlying relationships of the data, meaning\n", "that the average difference between a prediction and it's actual value\n", "is high.  \n", "\n", "When a model overfits, it is exhibiting high variance.  Because the model\n", "is trained too well on the training data, it is unable to generalize well\n", "to data the model wasn't trained on (aka test data).  As such, the \n", "average difference between any given prediction and the average prediction\n", "will be high.  \n", "'''\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### How do we diagnose overfitting and underfitting?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "'''\n", "We diagnose overfitting by looking at the difference\n", "between training results and testing results.  The larger\n", "the difference, the more overfitting is occuring.\n", "\n", "We diagnose underfitting by looking at the training results.\n", "The worse the training results, the more underfitting is\n", "occuring.\n", "'''"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### What are some techniques to mitigate over- and underfitting?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "'''\n", "In general, to mitigate underfitting, we make the model more complex\n", "- add variables\n", "- add interactions among variables\n", "- raise variables to higher powers\n", "- reduce the penalty to coefficient size (ie decrease regularization)\n", "\n", "In general, to mitigate overfitting, we make the model less complex\n", "- take out variables\n", "- take out interactions among variables\n", "- decrease the power variables are taken to\n", "- increase the penalty to coefficient size (ie increase regularization)\n", "\n", "'''"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Consider this graphic\n", "\n", "![](viz/diff_fits.png)\n", "\n", "Which is the most **complex** model?\n", "\n", "Which is the most **underfit** model?\n", "\n", "Which will have the **worst** training metrics?\n", "\n", "Which will have the **largest difference** \n", "in training and testing metrics?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["\n", "'''\n", "Most complex is the last model.  It has the most terms and the\n", "highest powers in those terms.  \n", "\n", "The most underfit model is the first model.  It least captures\n", "the underlying dynamics in the data, and it will have the \n", "highest average error in its training predictions.\n", "\n", "The worst training metrics, as metioned above, will occur in the first\n", "model.\n", "\n", "The largest difference in training and testing metrics will\n", "occur in the last model.  Because the last model is so fit\n", "to the training data, it will have good training metrics. However, it will \n", "generalize poorly to the testing data, leading to a high difference\n", "between training and testing metrics\n", "'''"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}